{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_component\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.identity import DefaultAzureCredential, EnvironmentCredential\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargar username/pass desde archivo .env\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cargar username/pass desde archivo .env\")\n",
    "load_dotenv(\"env.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comput_target(ml_client, name=\"cpu-cluster\", family='Standard_DS2_v2'):\n",
    "    cpu_compute_target = name\n",
    "    \n",
    "    try:\n",
    "        # let's see if the compute target already exists\n",
    "        cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    except Exception:\n",
    "        cpu_cluster = AmlCompute(\n",
    "            name=cpu_compute_target,\n",
    "            type=\"amlcompute\",\n",
    "            size=family,\n",
    "            min_instances=0,\n",
    "            max_instances=4,\n",
    "            idle_time_before_scale_down=180,\n",
    "            tier=\"Dedicated\",\n",
    "        )\n",
    "    \n",
    "        cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccessToken(token='eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IjlHbW55RlBraGMzaE91UjIybXZTdmduTG83WSIsImtpZCI6IjlHbW55RlBraGMzaE91UjIybXZTdmduTG83WSJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuYXp1cmUuY29tIiwiaXNzIjoiaHR0cHM6Ly9zdHMud2luZG93cy5uZXQvODRjYmMyMWItZmRmMy00MjcyLWFkMzQtZjRjMGZjZjcwZmExLyIsImlhdCI6MTY5OTQxNzAzMCwibmJmIjoxNjk5NDE3MDMwLCJleHAiOjE2OTk0MjA5MzAsImFpbyI6IkUyRmdZR0Q2S21UM2FqRnYyUG9Qelo4ZUtWNWVBQUE9IiwiYXBwaWQiOiIwODg0MjVjNS01NDkxLTQyMWUtYmUyMy0wMmEyZjAwODc5MjciLCJhcHBpZGFjciI6IjEiLCJpZHAiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC84NGNiYzIxYi1mZGYzLTQyNzItYWQzNC1mNGMwZmNmNzBmYTEvIiwiaWR0eXAiOiJhcHAiLCJvaWQiOiJiODc2NDFkMy0yOTUwLTQwNzQtYTI2OS01YjI2ODhjNjczOTMiLCJyaCI6IjAuQWIwQUc4TExoUFA5Y2tLdE5QVEFfUGNQb1VaSWYza0F1dGRQdWtQYXdmajJNQlBMQUFBLiIsInN1YiI6ImI4NzY0MWQzLTI5NTAtNDA3NC1hMjY5LTViMjY4OGM2NzM5MyIsInRpZCI6Ijg0Y2JjMjFiLWZkZjMtNDI3Mi1hZDM0LWY0YzBmY2Y3MGZhMSIsInV0aSI6InVIcTl0RHhQbVUtUUFKSkZxWnl6QUEiLCJ2ZXIiOiIxLjAiLCJ4bXNfY2FlIjoiMSIsInhtc190Y2R0IjoxNjk1MjU5MzQxfQ.f8D2-sIIkaWAydhDBK4BiYVNm9nk3P5VZPWV2paaBvONI7ck7dA9bZQ2hr9YfMtQz1te5W6zGhvn77Qu4AfbZdA1j1pTW0ypjhy_EvY1WBWafNMb99-CxYMkBkeJfxcypLhq_ugKpIB5B96d7F0q6m6K3LI56xgeJb5B6HPtzhZjrbIxRuK5uW_ts5EzBRowpW58MnKNKoQ-ZU4n6_-J9eEcRCyULnRXXNxqcQun-BODXlMef7h9p5f_TQe14hcdFhOOwqJem0EvKwOBsRUaYgZ9ibSutGttbwYDKb8lp86VyUssvQMbCLJf30jvQ-Hmb--nTHvSMqK8h_20ZTKTsw', expires_on=1699420928)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credential.get_token(\"https://management.azure.com/.default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target = get_comput_target(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_component = load_component(source=\"./train-component/dt_train.yml\")\n",
    "split_data_component = load_component(source=\"./split-data-component/split.yml\")\n",
    "score_component = load_component(source=\"./score-component/score.yml\")\n",
    "eval_model_component = load_component(source=\"./eval-model-component/eval.yml\")\n",
    "clean_data_component = load_component(source=\"./clean-data-component/clean_data.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a pipeline containing 3 nodes: Prepare data node, train node, and score node\n",
    "@pipeline(\n",
    "    default_compute='cpu-cluster',\n",
    ")\n",
    "def water_potability_decision_tree_dummy(pipeline_input_data):\n",
    "\n",
    "    clean_data_node = clean_data_component(\n",
    "        data_set = pipeline_input_data\n",
    "    )\n",
    "\n",
    "    split_data_node = split_data_component(\n",
    "        clean_data = clean_data_node.output.data_clean_output, # Directory\n",
    "        split_ratio_train = 0.8\n",
    "    )\n",
    "\n",
    "    train_node = train_component(\n",
    "        training_data=split_data_node.output.data_train, # File\n",
    "        criterion = 'entropy',\n",
    "        min_samples_split=2,\n",
    "        max_depth=None\n",
    "    )\n",
    "    \n",
    "    score_node = score_component(\n",
    "        test_data=split_data_node.output.data_test, # File\n",
    "        model_input=train_node.outputs.model_output # Folder\n",
    "    )\n",
    "\n",
    "    eval_node = eval_model_component(\n",
    "        scoring_result=score_node.outputs.score_output, # Folder\n",
    "        target_column = 'Potability'\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"correlation_graph\" : clean_data_node.outputs.corr_matrix_output,\n",
    "        \"model_pkl\" : train_node.outputs.model_output,\n",
    "        \"model_metrics\": eval_node.outputs.eval_output\n",
    "    }\n",
    "\n",
    "\n",
    "# create a pipeline\n",
    "water_potability_ds =  Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"azureml://subscriptions/df5b1289-646f-4999-a2a8-7eec46d13e15/resourcegroups/Azure-ML/workspaces/Azureml/datastores/workspaceblobstore/paths/UI/2023-11-08_041356_UTC/water_potability_ds.csv\",\n",
    "        )\n",
    "pipeline_job = water_potability_decision_tree_dummy(pipeline_input_data=water_potability_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "{\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Required input 'clean_data' for component 'split_data_node' not provided.\",\n      \"path\": \"jobs.split_data_node.inputs.clean_data\",\n      \"value\": null\n    },\n    {\n      \"message\": \"Required input 'training_data' for component 'train_node' not provided.\",\n      \"path\": \"jobs.train_node.inputs.training_data\",\n      \"value\": null\n    },\n    {\n      \"message\": \"Required input 'test_data' for component 'score_node' not provided.\",\n      \"path\": \"jobs.score_node.inputs.test_data\",\n      \"value\": null\n    }\n  ]\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:640\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[1;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_validation:\n\u001b[1;32m--> 640\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(job, raise_on_failure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    642\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:350\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[1;32m--> 350\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[0;32m    352\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:543\u001b[0m, in \u001b[0;36mJobOperations._validate\u001b[1;34m(self, job, raise_on_failure, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[39mreturn\u001b[39;00m git_code_validation_result\u001b[39m.\u001b[39mtry_raise(\n\u001b[0;32m    539\u001b[0m         raise_error\u001b[39m=\u001b[39mraise_on_failure,\n\u001b[0;32m    540\u001b[0m         error_func\u001b[39m=\u001b[39merror_func,\n\u001b[0;32m    541\u001b[0m     )\n\u001b[1;32m--> 543\u001b[0m validation_result \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39;49m_validate(raise_error\u001b[39m=\u001b[39;49mraise_on_failure)\n\u001b[0;32m    544\u001b[0m validation_result\u001b[39m.\u001b[39mmerge_with(git_code_validation_result)\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\entities\\_validation\\schema.py:119\u001b[0m, in \u001b[0;36mSchemaValidatableMixin._validate\u001b[1;34m(self, raise_error)\u001b[0m\n\u001b[0;32m    118\u001b[0m result\u001b[39m.\u001b[39mmerge_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_customized_validate())\n\u001b[1;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_raise(result, raise_error\u001b[39m=\u001b[39;49mraise_error)\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\entities\\_validation\\schema.py:106\u001b[0m, in \u001b[0;36mSchemaValidatableMixin._try_raise\u001b[1;34m(cls, validation_result, raise_error)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_raise\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[39mcls\u001b[39m, validation_result: MutableValidationResult, \u001b[39m*\u001b[39m, raise_error: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    105\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m MutableValidationResult:\n\u001b[1;32m--> 106\u001b[0m     \u001b[39mreturn\u001b[39;00m validation_result\u001b[39m.\u001b[39;49mtry_raise(raise_error\u001b[39m=\u001b[39;49mraise_error, error_func\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_create_validation_error)\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\entities\\_validation\\core.py:252\u001b[0m, in \u001b[0;36mMutableValidationResult.try_raise\u001b[1;34m(self, raise_error, error_func)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[39mreturn\u001b[39;00m ValidationError(message\u001b[39m=\u001b[39mmsg)\n\u001b[1;32m--> 252\u001b[0m     \u001b[39mraise\u001b[39;00m error_func(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m(),\n\u001b[0;32m    254\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mvalidation failed on the following fields: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_messages),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mValidationException\u001b[0m: {\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Required input 'clean_data' for component 'split_data_node' not provided.\",\n      \"path\": \"jobs.split_data_node.inputs.clean_data\",\n      \"value\": null\n    },\n    {\n      \"message\": \"Required input 'training_data' for component 'train_node' not provided.\",\n      \"path\": \"jobs.train_node.inputs.training_data\",\n      \"value\": null\n    },\n    {\n      \"message\": \"Required input 'test_data' for component 'score_node' not provided.\",\n      \"path\": \"jobs.score_node.inputs.test_data\",\n      \"value\": null\n    }\n  ]\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Y540\\Documents\\Diplomado ML\\Modulo 4\\Diplomado-ML-2023---Proyecto-2\\orchestrator.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Y540/Documents/Diplomado%20ML/Modulo%204/Diplomado-ML-2023---Proyecto-2/orchestrator.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipeline_job \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mcreate_or_update(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Y540/Documents/Diplomado%20ML/Modulo%204/Diplomado-ML-2023---Proyecto-2/orchestrator.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     pipeline_job, experiment_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpipeline_water_potability_dummy\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Y540/Documents/Diplomado%20ML/Modulo%204/Diplomado-ML-2023---Proyecto-2/orchestrator.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Y540/Documents/Diplomado%20ML/Modulo%204/Diplomado-ML-2023---Proyecto-2/orchestrator.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pipeline_job\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:350\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[0;32m    349\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[1;32m--> 350\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[0;32m    352\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[0;32m    353\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:709\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[1;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmarshmallow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m SchemaValidationError\n\u001b[0;32m    708\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n\u001b[1;32m--> 709\u001b[0m     log_and_raise_error(ex)\n\u001b[0;32m    710\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    711\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[1;32mc:\\Users\\Y540\\.conda\\envs\\ML-Azure\\lib\\site-packages\\azure\\ai\\ml\\_exception_helper.py:337\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[1;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m--> 337\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(formatted_error)\n",
      "\u001b[1;31mException\u001b[0m: {\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Required input 'clean_data' for component 'split_data_node' not provided.\",\n      \"path\": \"jobs.split_data_node.inputs.clean_data\",\n      \"value\": null\n    },\n    {\n      \"message\": \"Required input 'training_data' for component 'train_node' not provided.\",\n      \"path\": \"jobs.train_node.inputs.training_data\",\n      \"value\": null\n    },\n    {\n      \"message\": \"Required input 'test_data' for component 'score_node' not provided.\",\n      \"path\": \"jobs.score_node.inputs.test_data\",\n      \"value\": null\n    }\n  ]\n}"
     ]
    }
   ],
   "source": [
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"pipeline_water_potability_dummy\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
